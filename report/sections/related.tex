\section{RELATED WORK}\label{sec:related}

There are several cluster computing frameworks such as Hadoop, Apache Spark, Apache Storm, Samza, and Flink. These frameworks facilitate the combination of several independent computers into a unified system through software and networking. This architecture allows higher availability for greater performance computing and reality to provide greater computational power than the individual machines.   

Apache Hadoop is an open source, scalable and fault-tolerant framework that exclusively provides batch processing and efficiently processes large volumes of data on cluster commodity hardware and assures that data remains available in spite of inevitable host failures. 

Apache Storm is a stream processing framework that focuses on extremely low latency and could be the best option for workloads that require near real-time processing. It can handle very large quantities of data and deliver results with less latency than other solutions  

Apache Samza is a stream processing framework that is tightly tied to the Apache Kafka messaging system it is designed to guarantees Kafka with fault tolerance, buffering and state storage.

Apache Spark is a general purpose and lightning fast cluster computing system. It provides high-level APIs and is a next generation batch processing framework with stream processing capabilities.

Apache Flink is a stream processing framework that can also handle batch tasks, considering batches to simply be data streams with finite boundaries and therefore treats batch processing as a subset of stream processing.
