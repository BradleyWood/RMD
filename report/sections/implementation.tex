\section{IMPLEMENTATION}\label{sec:impl}

The project has been implemented on the Java Virtual Machine with a modular design allowing for
a separation of concerns.
In total, there are 5 modules including the load balancer, job server, the main client,
the Kotlin client (Kotlin DSL support), and the communications module.
Each module is responsible for one specific job, and they collectively work together.
Since the project is implemented on JVM, it can theoretically support any language
that executes on top of the JVM, and not just Java.
The implementation officially supports both the Java and Kotlin programming languages.

\subsection{Communications}\label{subsec:communcations}

Network communications is an import part of the distributed system.
The communications module has the job of guaranteeing that messages
are passed from client to server and are handled by the correct handler.
Networking is done on top of the TCP protocol, however, it is possible to
implement using UDP.
The UDP protocol would add extra challenges to the communications because
UDP does not guarantee the order of messages upon arrival.
This could be problematic if a job request came before the associated
code migration operation.

The communication protocol is a very simple request-reply protocol.
Each message contains the following information:
message length, request Id, and serialized message content.
The messages are serialized and deserialized using a framework call Fast-Serialization,
which has a greater performance than the native JVM serialization algorithms.

The communications layer only supports synchronous requests, however, this is acceptable
for asynchronous jobs because the requests are sent on top of the executor service (lightweight thread-pool).
To avoid busy waiting, the wait-notify pattern is used.
A thread that is waiting for a response from the server invokes wait(),
whilst notify() is called when the response is received from the server.
This allows any threads to sleep during the interim period, and to help
save computing resources.

\begin{minipage}{\linewidth}

    \setlength{\belowcaptionskip}{15pt plus 3pt minus 2pt}
    \captionof{table}{Message Format}
    \begin{tabular}{ c l }
        \hline
        \multicolumn{1}{c}{Number of Bytes} & \multicolumn{1}{c}{Content} \\
        \hline
        4 & Message Length (N) \\
        4 & Request Id \\
        N & Message Content \\
    \end{tabular}

\end{minipage}


\subsection{Client}\label{subsec:client}
The Client module is responsible for determining the method call sites at runtime from their
method reference, serializing classes and their dependencies, and performing the migration/job
requests to either a server or load balancer.
This module is dependent on both the communication module, and the load balancing module.
The communications module is used for all networking.
The load balancing module is also used on the client side to allow for use of multiple
job servers without requiring an external load balancer to act as the middleman.

To allow the user to maintain static type safety, method references and lambda expressions
are used to specify the call site of the job that is to be executed remotely.
The call site information is determined at runtime to avoid any sort of compiler
bootstrapping.
The call site information specifies the signature of a method, the method name, and it's location.
This information is required to perform the code migration process.
A function also may make use of any dependency, even if it is not defined as part of the Java
runtime environment.
These dependencies are determined by visiting all methods, fields, and instructions,
defined in the class file using the ASM bytecode manipulation and generation framework.
After the dependency graph is formed, the client is ready to perform a migration request.
When an asynchronous job request is sent to a server, its handler is processed by the executor service
(a lightweight thread-pool).

\subsubsection{Synchronous Java Example}

In this example, the function 'factorial' executed with an input of 6
in a blocking manor.
A method reference is used to tell the system what
code is to be executed.

\begin{lstlisting}
    a = delegate(this::factorial, 6)
    println("6! " + a);
\end{lstlisting}

\subsubsection{Asynchronous Java Example}

In this code snippet, the main calculation is done asynchronously
by the server and the client does not block while waiting for the reply.
the client is then free to do other tasks while the server completes the job.
Both the job and callback functions are defined via lambda expression, with
the function parameters in the middle.

\begin{lstlisting}
delegate((a, b) -> a * b,
    5, 9,
    n -> {
    // callback
    println("5 * 9 = " + n);
});
\end{lstlisting}

\subsection{Kotlin Client}\label{subsec:kotlinClient}
The Kotlin client module servers to provide extended support to the Kotlin
programming language.
This module defines an expressive Kotlin DSL (domain specific language) which
serves to make use of the expressive grammar defined by the Kotlin programming language.
This module is dependent upon the main Client module to handle any code migration and job requests.
The DSL is design to be extremely simple for users to understand.

\subsubsection{Synchronous Kotlin Example}

Since Kotlin has extremely expressive syntax, a function which accepts a
lambda expression can be written as a block with a body.
For example, code in the delegate block would be executed remotely in a blocking manor.

\begin{lstlisting}
val a = 100
val b = 200

val result = delegate {
    // blocking remote execution
    a * b
}

println("$a * $b = $result")
\end{lstlisting}

\subsubsection{Asynchronous Kotlin Example}

To execute an asynchronous job, the programmer can define code within an
'async' block and optionally provide a 'callback' block to aquire the result.

\begin{lstlisting}
val a = 10
val b = 20

async {
    a * b // executes remotely
} callback {
    // executes locally
    println("$a * $b = $it")
}
\end{lstlisting}

\subsection{Job Server}\label{subsec:jobServer}

It is the responsibility of the job server to handle incoming
migration requests and to perform the execution of any job requests.
Upon receiving a migration request, the job server attempts attempts to
load all classes specified in the request.
This is easily accomplished by providing a custom class loader
that searches the class map (key=class name, value=bytecode) instead
of the local file system.
In the unlikely event that a class fails to load, either because it is corrupted or
it's dependencies are missing, the job server will reply with a failure message.

After the migration action has been completed, clients can send a number of job requests
in parallel to the server.
Each job request contains the following information: the method name, the method signature
the name of it's declaring class, and the function parameters.
This information is required find the declaring class, and to invoke the method
by using reflection.
In the event that the class or method is not found, the server will send the failure
response.


\subsection{Load Balancer}\label{subsec:modules}

The load balancer has the important job of managing the use of resources
on the computing network.
This module depends upon the communication module to handle all network IO
between clients and job servers.
The load balancer accepts connections from clients and forwards their job
request based on resource availability.
It also also clients to self describe as a job server in order to allow for
resource donation.
To balance the computing load across several job servers, a round-robin
scheduling algorithm is provided as the default scheduling algorithm.
Advanced users can write and use their own scheduling algorithms via dependency
injection.
After a client initialized a connection, it must first send a migration request
to the load balancer before sending any job requests.
This protocol acts the same as direct communication between a client and server,
therefore the client does not need to distinguish between a job server or load
balancer.
The load balancer must verify that a job server has the required
code before forwarding a job request to the chosen server.
This is a problem because of the one-to-many relationship between the client
and job servers.
To solve this problem, the load balancer stores a map between
a JVM class name, and its bytecode instructions.
It also records a list of each class file that the job server has so it can
prevent migration of instructions that already exist on the job server.
The migration process is lazy, and only occurs when a job request
occurs to a server that has not seen the specific code before.
